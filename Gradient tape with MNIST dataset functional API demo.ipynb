{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf5c973",
   "metadata": {},
   "source": [
    "# Gradient Tape with Tensorflow - MNIST - Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401539c7",
   "metadata": {},
   "source": [
    "In this notebook, we look at an example of training a Tensorflow model using Gradient Tape\n",
    "To run this notebook, I am using the following package versions:\n",
    "\n",
    "* Tensorflow: 2.8.0\n",
    "\n",
    "* OpenCV: 4.6.0\n",
    "\n",
    "* Tensorflow datasets: 4.6.0\n",
    "\n",
    "There might be minor variations in the code for different versions of these packages.\n",
    "\n",
    "Also this implementation assumes some knowledge of Tensorflow Functional API. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc6c1a",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77b791dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "import matplotlib.ticker as mticker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83ca636",
   "metadata": {},
   "source": [
    "### Load, split and understand the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad602b1",
   "metadata": {},
   "source": [
    "Under this section we load the dateset from tensorflow datasets and split the data into **train** and **test**. For more information on how the split is performed check out this link: https://github.com/tensorflow/datasets/blob/master/docs/splits.md\n",
    "\n",
    "Once we have performed the split we want to get a bit more information on how the data is stored after loading. Understanding the datatype beforehand cause prevent a lot of issues from occuring later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35c203a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to ~\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976547b1d3984155ad0503d54d885261",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9831923f3a674c6cb896bb46f9d16d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ab0dd058a3430da00bad00958f0e0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~\\tensorflow_datasets\\mnist\\3.0.1.incomplete7Y0TW5\\mnist-train.tfrecord*...:   0%|          | 0/6000…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling ~\\tensorflow_datasets\\mnist\\3.0.1.incomplete7Y0TW5\\mnist-test.tfrecord*...:   0%|          | 0/10000…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to ~\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "train_data, info = tfds.load(\"mnist\", split = \"train\", with_info = True)\n",
    "test_data = tfds.load(\"mnist\", split = \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3009177",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset element_spec={'image': TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None)}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b026e35a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='mnist',\n",
       "    full_name='mnist/3.0.1',\n",
       "    description=\"\"\"\n",
       "    The MNIST database of handwritten digits.\n",
       "    \"\"\",\n",
       "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
       "    data_path='~\\\\tensorflow_datasets\\\\mnist\\\\3.0.1',\n",
       "    file_format=tfrecord,\n",
       "    download_size=11.06 MiB,\n",
       "    dataset_size=21.00 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@article{lecun2010mnist,\n",
       "      title={MNIST handwritten digit database},\n",
       "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
       "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
       "      volume={2},\n",
       "      year={2010}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80405e18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = info.features[\"label\"].num_classes\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c3dd3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = info.features[\"label\"].names\n",
    "class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bba137",
   "metadata": {},
   "source": [
    "### Data formatting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b97a53",
   "metadata": {},
   "source": [
    "We have seen earlier that the images are of size 28*28. Here we format the images such that it can be consumed in the input layer of our model. For the sake of understanding, we will create a dummy tensor with the same shape as the input image, pass it through the formatting function and understand the dimensions of the input to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c8edcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_image(data):\n",
    "    \"\"\"\n",
    "       Function to reshape, format and normalize input images to make it compatible with the deep learning model\n",
    "       Inputs:\n",
    "       data: Input image\n",
    "       Outputs:\n",
    "       image: Formatted image\n",
    "       data[\"label\"]: Training label associated with the image\n",
    "    \"\"\"\n",
    "    image = data[\"image\"]\n",
    "    image = tf.reshape(image, [-1])\n",
    "    image = tf.cast(image, 'float32')\n",
    "    image = image / 255.0\n",
    "    return image, data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b988334",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_tensor=tf.ones([28, 28,1], tf.int32)*255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc69d064",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_dict={\"image\":dummy_tensor, \"label\":1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c307a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_dummy=format_image(dummy_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bd767da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([784])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_dummy[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295bfa58",
   "metadata": {},
   "source": [
    "If you have any issues understanding the different stages of the function you can add print statments after each step. Remember to remove/comment them out before going to the next cell though!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5163df71",
   "metadata": {},
   "source": [
    "Now lets apply the ***format_image*** function on the entire train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "40b6fee2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "\n",
    "train_data = train_data.map(format_image)\n",
    "test_data = test_data.map(format_image)\n",
    "train = train_data.shuffle(buffer_size=1024).batch(batch_size)\n",
    "test =  test_data.batch(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b72b71e",
   "metadata": {},
   "source": [
    "### Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "12049284",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the model,\n",
    "def base_model():\n",
    "    \"\"\"\n",
    "    Define the model architecture here\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=(784,), name='digits')\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='dense_1')(inputs)\n",
    "    x = tf.keras.layers.Dense(64, activation='relu', name='dense_2')(x)\n",
    "    outputs = tf.keras.layers.Dense(10, activation='softmax', name='predictions')(x)\n",
    "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53447434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Optimizer and Loss Function\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6c34dadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Metrics \n",
    "train_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "val_acc_metric = tf.keras.metrics.SparseCategoricalAccuracy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6052b0d3",
   "metadata": {},
   "source": [
    "### Define the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2814933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gradient(optimizer, model, x, y):\n",
    "    \"\"\"\n",
    "    Function for computing gradient and updating the weights\n",
    "    \"\"\"\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Get model prediction and compute the loss\n",
    "        logits = model(x)\n",
    "        loss_value = loss_object(y_true=y, y_pred=logits)\n",
    "    # Calculate the gradient using tape.gradient and then update the model weights using our optimizer\n",
    "    gradients = tape.gradient(loss_value, model.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights))  \n",
    "    return logits, loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e99f77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data_for_one_epoch():\n",
    "    \"\"\"\n",
    "    Function for computing the gradient and updating weights in each epoch. \n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    # Iterate over batches of the dataset and call apply_gradient function\n",
    "    for step, (x_batch_train, y_batch_train) in enumerate(train):\n",
    "        logits, loss_value = apply_gradient(optimizer, model, x_batch_train, y_batch_train)     \n",
    "        losses.append(loss_value)\n",
    "        train_acc_metric(y_batch_train, logits)\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb18409b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_validation():\n",
    "    \"\"\"\n",
    "    Function for validation\n",
    "    \"\"\"\n",
    "    losses = []\n",
    "    for x_val, y_val in test:\n",
    "        val_logits = model(x_val)\n",
    "        val_loss = loss_object(y_true=y_val, y_pred=val_logits)\n",
    "        losses.append(val_loss)\n",
    "        val_acc_metric(y_val, val_logits)\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2948628a",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f52f516",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of epoch 0\n",
      "\n",
      " Epoch 0: Train loss: 0.3165  Validation Loss: 0.1763, Train Accuracy: 0.9097, Validation Accuracy 0.9465\n",
      "Start of epoch 1\n",
      "\n",
      " Epoch 1: Train loss: 0.1423  Validation Loss: 0.1180, Train Accuracy: 0.9579, Validation Accuracy 0.9649\n",
      "Start of epoch 2\n",
      "\n",
      " Epoch 2: Train loss: 0.1047  Validation Loss: 0.1030, Train Accuracy: 0.9695, Validation Accuracy 0.9700\n",
      "Start of epoch 3\n",
      "\n",
      " Epoch 3: Train loss: 0.0830  Validation Loss: 0.0953, Train Accuracy: 0.9751, Validation Accuracy 0.9710\n",
      "Start of epoch 4\n",
      "\n",
      " Epoch 4: Train loss: 0.0672  Validation Loss: 0.0925, Train Accuracy: 0.9804, Validation Accuracy 0.9729\n",
      "Start of epoch 5\n",
      "\n",
      " Epoch 5: Train loss: 0.0563  Validation Loss: 0.0868, Train Accuracy: 0.9830, Validation Accuracy 0.9739\n",
      "Start of epoch 6\n",
      "\n",
      " Epoch 6: Train loss: 0.0482  Validation Loss: 0.0946, Train Accuracy: 0.9848, Validation Accuracy 0.9722\n",
      "Start of epoch 7\n",
      "\n",
      " Epoch 7: Train loss: 0.0400  Validation Loss: 0.0955, Train Accuracy: 0.9877, Validation Accuracy 0.9727\n",
      "Start of epoch 8\n",
      "\n",
      " Epoch 8: Train loss: 0.0329  Validation Loss: 0.0896, Train Accuracy: 0.9901, Validation Accuracy 0.9744\n",
      "Start of epoch 9\n",
      "\n",
      " Epoch 9: Train loss: 0.0295  Validation Loss: 0.0956, Train Accuracy: 0.9911, Validation Accuracy 0.9735\n"
     ]
    }
   ],
   "source": [
    "model = base_model()\n",
    "\n",
    "# Iterate over epochs\n",
    "epochs = 10\n",
    "epochs_val_losses, epochs_train_losses = [], []\n",
    "for epoch in range(epochs):\n",
    "    print('Start of epoch %d' % (epoch,))\n",
    "    \n",
    "    #Perform training using gradient tape\n",
    "    losses_train = train_data_for_one_epoch()\n",
    "    train_acc = train_acc_metric.result()\n",
    "    \n",
    "    #Perform validation\n",
    "    losses_val = perform_validation()\n",
    "    val_acc = val_acc_metric.result()\n",
    "    \n",
    "    #Compute mean training and validation loss in the epoch \n",
    "    losses_train_mean = np.mean(losses_train)\n",
    "    losses_val_mean = np.mean(losses_val)\n",
    "    epochs_val_losses.append(losses_val_mean)\n",
    "    epochs_train_losses.append(losses_train_mean)\n",
    "\n",
    "    print('\\n Epoch %s: Train loss: %.4f  Validation Loss: %.4f, Train Accuracy: %.4f, Validation Accuracy %.4f' % (epoch, float(losses_train_mean), float(losses_val_mean), float(train_acc), float(val_acc)))\n",
    "  \n",
    "    train_acc_metric.reset_states()\n",
    "    val_acc_metric.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f88d56a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plots for Evaluation\n",
    "def plot_metrics(train_metric, val_metric, metric_name, title, ylim=5):\n",
    "    plt.title(title)\n",
    "    plt.ylim(0,ylim)\n",
    "    plt.gca().xaxis.set_major_locator(mticker.MultipleLocator(1))\n",
    "    plt.plot(train_metric,color='blue',label=metric_name)\n",
    "    plt.plot(val_metric,color='green',label='val_' + metric_name)\n",
    "\n",
    "plot_metrics(epochs_train_losses, epochs_val_losses, \"Loss\", \"Loss\", ylim=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931842c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "cv2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
